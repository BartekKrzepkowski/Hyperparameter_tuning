{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian optimization is a probabilistic model based approach for finding the minimum of any function that returns a real-value metric.<br> This function may be as simple as $f(x) = x^2$, or it can be as complex as the validation error of a deep neural network with respect to hundreds of model architecture and hyperparameter choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that this probabalilistic approach is more efficient than manual, random, or grid search, with regards to:<br>\n",
    "> Better overall performance on the test set<br>\n",
    "> Less time required for optimization\n",
    "\n",
    "Hyperopt is a one of the libraries that allows applications of Bayesian optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian optimization, optimizes hypothesis, by building a probability model of the objective function that maps input values to a probability of a loss: $P(loss | input \\ values)$.<br> \n",
    "The probability model, also called the surrogate or response surface, is easier to optimize than the actual objective function.<br>\n",
    "Bayesian methods select the next values to evaluate by applying a criteria (usually Expected Improvement) to the surrogate.<br>\n",
    "The concept is to limit evals of the objective function by spending more time choosing the next values to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_colab = {'booster': 'gbtree',\n",
    " 'colsample_bytree': 0.7000000000000001,\n",
    " 'eval_metric': 'auc',\n",
    " 'gamma': 0.0,\n",
    " 'learning_rate': 0.082,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 8.0,\n",
    " 'n_estimators': 1920,\n",
    " 'nthread': -1,\n",
    " 'objective': 'binary:logistic',\n",
    " 'reg_lambda': 5.5,\n",
    " 'scale_pos_weight': 1,\n",
    " 'subsample': 0.708767041292768}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, DMatrix\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "from hyperopt import hp, tpe, Trials\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_playground/dane_zad1.csv\"\n",
    "SONAR_DATA_PATH = \"data_playground/sonar.csv\"\n",
    "FRAUD_DATA_PATH = \"data_playground/creditcard.csv\"\n",
    "DIABETES_DATA_PATH = \"data_playground/diabetes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_data(data_path, encoder=None):\n",
    "    df = pd.read_csv(data_path)\n",
    "    data = df.values\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    if encoder:\n",
    "        X, y = encoder(X, y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_encoder(X, y):\n",
    "    X = X.astype(float)\n",
    "    return X, y\n",
    "\n",
    "# toy dataset\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = load_preprocess_data(DATA_PATH, encoder=toy_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonar_encoder(X, y):\n",
    "    X = X.astype(float)\n",
    "    y = y == y[0]\n",
    "    return X, y\n",
    "\n",
    "# sonar dataset\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = load_preprocess_data(SONAR_DATA_PATH, encoder=sonar_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud dataset\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = load_preprocess_data(FRAUD_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes dataset\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = load_preprocess_data(DIABETES_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_params(params):\n",
    "#     params[\"gamma\"] = np.log(params[\"gamma\"])\n",
    "#     params[\"learning_rate\"] = np.log(params[\"learning_rate\"])\n",
    "    params[\"n_estimators\"] = int(params[\"n_estimators\"])\n",
    "    params[\"max_depth\"] = int(params[\"max_depth\"])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parameters(params):\n",
    "    params = transform_params(params)\n",
    "    \n",
    "    clf_xgb = XGBClassifier(**params)\n",
    "        \n",
    "    eval_set  = [( x_train, y_train), (x_val, y_val)]\n",
    "    \n",
    "    clf_xgb.fit(x_train, y_train,\n",
    "            eval_set=eval_set, eval_metric=\"auc\", \n",
    "            early_stopping_rounds=50, verbose=False)\n",
    "    y_prob = clf_xgb.predict_proba(x_test)[:,1]\n",
    "    \n",
    "#     fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "#     xgb.plot_importance(clf_xgb, ax=ax)\n",
    "    \n",
    "    return roc_auc_score(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space = {\n",
    "    \"booster\": 'gbtree',       \n",
    "    \"objective\": 'binary:logistic',\n",
    "    \"eval_metric\": 'auc',\n",
    "    \"nthread\": -1,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 100, \n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"scale_pos_weight\": 1,\n",
    "    'reg_lambda': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimum number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_estimators(params, cv_folds=5, early_stopping_rounds=50):\n",
    "    params = transform_params(params)\n",
    "    \n",
    "    clf_xgb = XGBClassifier(**params)\n",
    "        \n",
    "    dtrain = DMatrix(x_train, label=y_train)\n",
    "    xgb_param = clf_xgb.get_xgb_params()\n",
    "    \n",
    "    cvresult = xgb.cv(xgb_param, dtrain, num_boost_round=clf_xgb.get_xgb_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "    clf_xgb.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    return clf_xgb.get_xgb_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = find_n_estimators(current_space)\n",
    "current_space[\"n_estimators\"] = params[\"n_estimators\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = transform_params(params)\n",
    "\n",
    "    clf_xgb = XGBClassifier(**params)\n",
    "\n",
    "    eval_set  = [( x_train, y_train), (x_val, y_val)]\n",
    "\n",
    "    clf_xgb.fit(x_train, y_train,\n",
    "            eval_set=eval_set, eval_metric=\"auc\", \n",
    "            early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "    pred = clf_xgb.predict_proba(x_val)[:,1]\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "#     print(\"SCORE:\", auc)\n",
    "\n",
    "    return{'loss':1-auc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={\n",
    "        'max_depth': hp.quniform(\"max_depth\", 1, 30, 1),\n",
    "        'min_child_weight': hp.quniform ('min_child_weight', 1, 10, 1),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"max_depth\"] = space[\"max_depth\"]\n",
    "current_space[\"min_child_weight\"] = space[\"min_child_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=current_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"max_depth\"] = best[\"max_depth\"]\n",
    "current_space[\"min_child_weight\"] = best[\"min_child_weight\"]\n",
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={\n",
    "    'gamma': hp.quniform('gamma', 0.0, 1, 0.05)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"gamma\"] = space[\"gamma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=current_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"gamma\"] = best[\"gamma\"]\n",
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={\n",
    "        'subsample': hp.uniform ('subsample', 0.7, 1),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 1, 0.05)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"subsample\"] = space[\"subsample\"]\n",
    "current_space[\"colsample_bytree\"] = space[\"colsample_bytree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=current_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"subsample\"] = best[\"subsample\"]\n",
    "current_space[\"colsample_bytree\"] = best[\"colsample_bytree\"]\n",
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={\n",
    "        'reg_lambda' :  hp.quniform('reg_lambda', 0, 10, 0.5)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"reg_lambda\"] = space[\"reg_lambda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=current_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"reg_lambda\"] = best[\"reg_lambda\"]\n",
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune lr and n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, current_space[\"learning_rate\"], 0.002),\n",
    "    \"n_estimators\": hp.quniform(\"n_estimators\", current_space[\"n_estimators\"], 5000, 20),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"learning_rate\"] = space[\"learning_rate\"]\n",
    "current_space[\"n_estimators\"] = space[\"n_estimators\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=current_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"learning_rate\"] = best[\"learning_rate\"]\n",
    "current_space[\"n_estimators\"] = best[\"n_estimators\"]\n",
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"learning_rate\"] = best[\"learning_rate\"]\n",
    "current_space[\"n_estimators\"] = best[\"n_estimators\"]\n",
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space[\"learning_rate\"] = best[\"learning_rate\"]\n",
    "current_space[\"n_estimators\"] = best[\"n_estimators\"]\n",
    "test_parameters(current_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulating an optimization problem in Hyperopt requires four parts:<br>\n",
    "> Objective Function: takes in an input and returns a loss to minimize <br>\n",
    "> Domain space: the range of input values to evaluate<br>\n",
    "> Optimization Algorithm: the method used to construct the surrogate function and choose the next values to evaluate<br>\n",
    "> Results: score, value pairs that the algorithm uses to build the model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_space ={\n",
    "        \"booster\": 'gbtree',       \n",
    "        \"objective\": 'binary:logistic',\n",
    "        \"eval_metric\": 'auc',\n",
    "        \"nthread\": -1,        \n",
    "        'max_depth': hp.quniform(\"max_depth\", 1, 30, 1),\n",
    "        'min_child_weight': hp.quniform ('min_child_weight', 1, 10, 1),\n",
    "        'gamma': hp.quniform('gamma', 0.0, 1, 0.05),\n",
    "        'subsample': hp.uniform ('subsample', 0.7, 1),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 1, 0.05),\n",
    "        'reg_lambda' :  hp.quniform('reg_lambda', 0, 10, 0.5),\n",
    "        'learning_rate': hp.quniform('learning_rate', 0.001, 0.5, 0.002),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 10, 1000, 20),\n",
    "        \"scale_pos_weight\": hp.quniform('scale_pos_weight', 0.0, 1, 0.05),\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    space = transform_params(params)\n",
    "\n",
    "    clf_xgb = XGBClassifier(**params)\n",
    "\n",
    "    eval_set  = [( x_train, y_train), (x_val, y_val)]\n",
    "\n",
    "    clf_xgb.fit(x_train, y_train,\n",
    "            eval_set=eval_set, eval_metric=\"auc\", \n",
    "            early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "    pred = clf_xgb.predict_proba(x_val)[:,1]\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "#     print(\"SCORE:\", auc)\n",
    "\n",
    "    return{'loss':1-auc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=domain_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best[\"booster\"] = domain_space[\"booster\"]\n",
    "best[\"objective\"] = domain_space[\"objective\"]\n",
    "best[\"eval_metric\"] = domain_space[\"eval_metric\"]\n",
    "best[\"nthread\"] = domain_space[\"nthread\"]\n",
    "test_parameters(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory efficient approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_space ={\n",
    "        \"booster\": 'gbtree',       \n",
    "        \"objective\": 'binary:logistic',\n",
    "        \"eval_metric\": 'auc',\n",
    "        \"nthread\": -1,        \n",
    "        'max_depth': hp.quniform(\"max_depth\", 1, 30, 1),\n",
    "        'min_child_weight': hp.quniform ('min_child_weight', 1, 10, 1),\n",
    "        'gamma': hp.quniform('gamma', 0.0, 1, 0.05),\n",
    "        'subsample': hp.uniform ('subsample', 0.7, 1),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 1, 0.05),\n",
    "        'lambda' :  hp.quniform('lambda', 0, 10, 0.5),\n",
    "        'eta': hp.quniform('eta', 0.001, 0.5, 0.002),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 10, 1000, 20),\n",
    "        \"scale_pos_weight\": hp.quniform('scale_pos_weight', 0.0, 1, 0.05),\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_me(space):\n",
    "    space = transform_params(space)\n",
    "    dtrain = DMatrix(x_train, label=y_train)\n",
    "    dval = DMatrix(x_val, label=y_val)\n",
    "    evallist  = [(dtrain,'train'),(dval,'eval')]\n",
    "    clf = xgb.train(params=space, dtrain=dtrain, evals=evallist, early_stopping_rounds=50, verbose_eval=False)\n",
    "    \n",
    "    pred = clf.predict(dval)\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "\n",
    "    \n",
    "    return{'loss':1-auc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective_me,\n",
    "            space=domain_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best[\"booster\"] = domain_space[\"booster\"]\n",
    "best[\"objective\"] = domain_space[\"objective\"]\n",
    "best[\"eval_metric\"] = domain_space[\"eval_metric\"]\n",
    "best[\"nthread\"] = domain_space[\"nthread\"]\n",
    "test_parameters(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Visualizaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_results = pd.DataFrame({'loss': [x['loss'] for x in trials.results], 'iteration': trials.idxs_vals[0]['max_depth'],\n",
    "                           **trials.idxs_vals[1]})\n",
    "                            \n",
    "tpe_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = dict(zip(tpe_results.columns[2:], [\"green\", \"red\", \"m\", \"purple\", \"orange\", \"g\"]))\n",
    "figsize=(10,10)\n",
    "ax=None\n",
    "for col in tpe_results.columns[2:]:\n",
    "    ax = tpe_results.plot.scatter(x=\"iteration\", y=col, grid=True, xticks=range(tpe_results.shape[0]), ax=ax, c=color[col], label=col, figsize=figsize, s=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_results.iloc[:,2:].plot.hist(bins=50, figsize=(10,10), edgecolor = 'k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={\n",
    "        \"booster\"   : 'gbtree',       \n",
    "        \"objective\"   : 'binary:logistic',\n",
    "        \"eval_metric\" : 'auc',\n",
    "        \"nthread\"     : -1,\n",
    "        \"n_estimators\" : 100, \n",
    "        'max_depth': hp.quniform(\"max_depth\", 1, 30, 1),\n",
    "        'min_child_weight': hp.quniform ('min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('subsample', 0.8, 1),\n",
    "        'gamma': hp.quniform('gamma', 0.0, 1, 0.05),\n",
    "        'lambda' :  hp.quniform('lambda', 0, 10, 1),\n",
    "        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        'learning_rate': hp.quniform('learning_rate', 0.001, 0.2, 0.01),\n",
    "        'reg_alpha': hp.hp.uniform ('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': hp.hp.uniform ('reg_lambda', 0.0, 1.0)\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded clf in xgb lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator, xgboost_classification\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    return 1-roc_auc_score(y_true, y_pred)\n",
    "\n",
    "estim = HyperoptEstimator(classifier=xxx,\n",
    "                          preprocessing=[],\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=10,\n",
    "                          trial_timeout=300,\n",
    "                          loss_fn=auc)\n",
    "\n",
    "estim.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
